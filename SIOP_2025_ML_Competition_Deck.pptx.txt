SIOP 2025 ML Competition
Ivan Hernandez, Isaac Thompson
Sebastian Marin


NC Pine Trees: Tall! 

The Value of Good Trees
Tall trees are used for: 
Shelter (Animals and Humans) 
Lumber 
Heat (cooking and warmth)  
Paper for knowledge


Purpose of this Competition: Selection Assessment is at a Crossroads
Is selection assessment dead? Check your bias. there are already tools that can: 
Score super high on the SAT/ACT/GRE/MCAT/etc 
Score personality
Do coding exams
Structure your experience for an interview
Picture on the right: Roy Lee beats tech assessments‚Ä¶ 


The Reason for this Competition 
How do we answer that question?
How about when a new model comes out?
Comprehensive Assessment Archive
almost 1k jobs 
Algorithm Performance Testing 
how well approaches could get those jobs
Maybe when we try 10k different approaches, novelty will find sunshine and grow to utility and benefit

History of the Machine Learning Competition
2018
Predict turnover 
(Eli Lilly & Co.)
Predict self-report personality from open-ended interview (Shaker/Modern Hire)
2019
2020-2021
Predict who to hire with diversity and validity optimized 
(Walmart)
2023
Predict AC ratings of decision making from open-ended text 
(DDI)
2024
Evaluate LLMs via benchmarks 
(HackerRank, Virginia Tech, DDI) 
2025
Beat the Selection Algorithm with AI 

The Machine Learning Competition
A data set is released with a problem statement (training set)
Community attempts to solve the problem statement, empirically
Scaled evaluation of approaches is accomplished online on a public leaderboard (dev phase)
Best generalizable solution wins as teams submit to a final private leaderboard (test phase)
Winners are decided based on the empirical quality of their work
The benchmark lives beyond the competition as these solutions are released to the public and new methods become available 


This Year
Open to *Any* Computational Approach and not restricted to a specific type of model or AI
Multiple benchmarks of diverse problem sets related to applicant tasks (with unique aspects, red herrings, and anti LLM measures)
Large dataset with limit on computational complexity
High opportunity for development with competitors able to submit up to 50 submissions per day
Low precise feedback on specific tasks with score provided across all jobs


Competition Data
Honesty score: Composite of overclaiming and response patterns
Accuracy of detecting job-related technologies versus AI generated technologies
Pretrained Random Forest (Nie et al., 2025)
Personality: Fit metric based on distance to profile‚Äôs predicted personality via indirect indicators (e.g., RIASEC)
IPIP-120
GenAI generated Ipsative Questions
Personality-specific interview questions
Cognitive Ability: Ability metric based on percentage of cognitive ability answered correctly
Numeric Patterns
Applying mathematical operations
Unscrambling/Anagrams
Skills and Ability: Ability metric based on competencies and resume
Answers to interview questions scored with pretrained BARS cross-encoder
Number of indicated technologies on resume / total possible technologies

Overall Score = Honest probability * (Personality * .33) + (Cognitive Ability * . 33) + (Skills and Ability * .33)

Training Leaderboard Progress Over Time

Training Leaderboard Progress Over Time By Task

Training Leaderboard Progress By Team

Pearson‚Äôs Correlation Between Score and Number of Train Submissions
Number of Submissions

Top 15 Teams on Private/Test Leaderboard
Rank
Team
Final Score
1
????
????
2
????
????
3
????
????
4
????
????
5
SIOP_ML
0.72
6
ILMN Insights
0.72
7
Team Procruistination
0.52
8
APRIL
0.49
9
OptimalFit
0.30
10
EigenVictory
0.27
11
IGEZ
0.22
12
SunRice
0.19
13
Elon-AI
0.12
14
The Baker Street Students
0.08
15
Praxis
0.03

The Finalists

The Top 4 Teams
(From 4th - 1st)

Fourth Place
ReLULU
Final Score = .73
Team Members:
Bao Ho
Yizhen Egyn Zhu

Third Place
Care Mice
Final Score = .760
Team Members:
Matthew Arsenault
Farshad Koohifar 
Suhas Yogish


Second Place
Hungry Llama
Final Score = .764
Team Members:
Shane Halder
Joe Lchman
Jen Gibson
Nick McCann

Hungry Llama / ForsMarsh

First Place
Wonderlic ML
Final Score = .89
Team Members:
Guglielmo Menchetti
Lea Cleary
Michael Grossenbacher
Tonya Lucas
Craig Dawson


Top 15 Teams on Private/Test Leaderboard
Rank
Team
Final Score
1
Wonderlic MLü•á
0.89
2
HungryLlamaü•à
0.764
3
Care Miceü•â
0.760
4
ReLULU üéñÔ∏è
0.73
5
SIOP_ML
0.72
6
ILMN Insights
0.72
7
Team Procruistination
0.52
8
APRIL
0.49
9
OptimalFit
0.30
10
EigenVictory
0.27
11
IGEZ
0.22
12
SunRice
0.19
13
Elon-AI
0.12
14
The Baker Street Students
0.08
15
Praxis
0.03

Panelist Q&A
Audience, Any Questions for our Panelists?

Closing Remarks
Best Test Honest = 1.0
Best Test Personality = .83
Best Test Skills  = 1.0
Best Test Cognitive Ability = .97

H * (P *.33 + S * .33 + CA * .33)
Theoretical Best Overall Score = .924

Panelist Q&A
How will LLMs change the science and practice of I-O?
How did you do it, what was your secret sauce?
What would you have done differently?
Where do you see these methods being applied in I-O? 
What most impressed you most about the other teams‚Äô approaches?
What is your takeaway from participating and winning a ML competition?
What would you like to see in future I-O ML competitions?


