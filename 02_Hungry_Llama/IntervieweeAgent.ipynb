{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Vr3NQud7nSce",
        "oDPAxdCten44",
        "JECp3DljochJ",
        "YIaDk9oEe_u9",
        "hETXXqRX77Hq",
        "FnuN2MltGeOX",
        "gXD-CTVOSaWp",
        "-LIFq3Cx8Wex",
        "sChxKoVHWElK",
        "SMzztO__-NWx",
        "NrlXrB97pQ1G",
        "bhRkdlENmFsT",
        "x6ayyYVRwcHD",
        "TIPMMoaD_l4P"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install Packages"
      ],
      "metadata": {
        "id": "Vr3NQud7nSce"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SVpv_G2hnCzI"
      },
      "outputs": [],
      "source": [
        "!pip -q install pandas\n",
        "!pip -q install requests\n",
        "!pip -q install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Statements"
      ],
      "metadata": {
        "id": "Mor26b7wndPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "import pandas as pd\n",
        "from pandas.io.formats import excel\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "ROVSCYIUneqQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config"
      ],
      "metadata": {
        "id": "iYAMwDkUnxQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_folder  = './'\n",
        "output_folder = './'\n",
        "\n",
        "#TODO: Update Phase and OpenAI API Key\n",
        "#submit_phase = 'dev'\n",
        "submit_phase = 'test'\n",
        "\n",
        "openai_api_key = userdata.get('OPENAI_TOKEN')\n",
        "\n",
        "job_listings_path = f\"{input_folder}{submit_phase}_companies_jobs_and_ads.xlsx\"\n",
        "job_applications_path = f\"{input_folder}{submit_phase}_jobapplication.xlsx\"\n",
        "combined_path = f\"{input_folder}{submit_phase}_combined.xlsx\"\n",
        "job_skills_path = f\"{input_folder}{submit_phase}_job_skills.xlsx\"\n",
        "job_skills_unique_path = f\"{input_folder}{submit_phase}_job_skills_unique.xlsx\"\n",
        "job_skills_answers_path = f\"{input_folder}{submit_phase}_job_skills_answers.xlsx\"\n",
        "interview_path = f\"{input_folder}{submit_phase}_interview.xlsx\"\n",
        "interview_answers_path = f\"{input_folder}{submit_phase}_interview_answers.xlsx\"\n",
        "personality_likert_path = f\"{input_folder}{submit_phase}_personality_likert.xlsx\"\n",
        "personality_likert_answers_path = f\"{input_folder}{submit_phase}_personality_likert_answers.xlsx\"\n",
        "personality_choice_path = f\"{input_folder}{submit_phase}_personality_choice.xlsx\"\n",
        "personality_choice_answers_path = f\"{input_folder}{submit_phase}_personality_choice_answers.xlsx\"\n",
        "\n",
        "answers_path = f\"{input_folder}{submit_phase}_answers.xlsx\"\n",
        "submit_path = f\"{input_folder}{submit_phase}_submit.xlsx\"\n",
        "\n",
        "unscramble_lookup_path = f\"{input_folder}unscramble_dictionary.xlsx\"\n",
        "\n",
        "id_col = \"Id\"\n",
        "job_title_col = \"Job\"\n",
        "role_title_col = \"Role Title\"\n",
        "department_col = \"Department\"\n",
        "company_col = \"Company\"\n",
        "format_col = \"Format\"\n",
        "item_col = \"Item\"\n",
        "question_col = \"Question\"\n",
        "response_col = \"Response\"\n",
        "revenue_col = \"Annual Revenue in Billions\"\n",
        "employee_count_col = \"Employee Count\"\n",
        "mission_col = \"Mission\"\n",
        "products_col = \"Products\"\n",
        "advertisement_col = \"Advertisement\"\n",
        "management_col = \"ManagementLevel\"\n",
        "company_size_col = \"CompanySize\"\n",
        "prompt_col = \"Prompt\"\n",
        "duration_col = \"Duration\"\n",
        "skills_col = \"AllSkills\"\n",
        "skills_count_col = \"SkillsCount\"\n",
        "basic_skills_col = \"BasicSkills\"\n",
        "department_function_col = \"Department Function\"\n",
        "required_skills_col = \"RequiredSkills\"\n",
        "response_len_col = \"ResponseLength\"\n",
        "count_col = \"Count\"\n",
        "\n",
        "job_info_cols       = [job_title_col, company_col, mission_col, products_col, revenue_col, employee_count_col, department_col, department_function_col, advertisement_col, skills_col, management_col, company_size_col]\n",
        "submit_keep_cols    = [job_title_col, question_col, format_col, item_col, response_col]\n",
        "\n",
        "openai_llm_gpt_4o = \"gpt-4o\"\n",
        "openai_llm_gpt_4o_mini = \"gpt-4o-mini\"\n",
        "openai_llm_gpt_o3_mini = \"o3-mini\"\n",
        "openai_llm_gpt_45 = \"gpt-4.5-preview\""
      ],
      "metadata": {
        "id": "tcBtG1Aon3BU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup and Initialization\n"
      ],
      "metadata": {
        "id": "oDPAxdCten44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove default Excel styling\n",
        "excel.ExcelFormatter.header_style = None\n",
        "\n",
        "# Initialize Open AI API client\n",
        "openai_client = OpenAI(api_key=openai_api_key)\n",
        "\n",
        "# Load Unscramble Dictionary\n",
        "unscramble_dict = pd.read_excel(unscramble_lookup_path, index_col=0).to_dict()\n",
        "\n",
        "# Load Skills\n",
        "excluded_skills_starts_with = [\"project\", \"data\", \"customer\", \"sales\", \"task\", \"competitive\", \"content\", \"collaborative\", \"strategic\", \"client\", \"compliance\", \"responsive\"]\n",
        "\n",
        "# Item Prefixes\n",
        "personality_likert_item_prefix = \"Personality Likert\"\n",
        "personality_choice_item_prefix = \"Personality Choice\"\n",
        "job_readiness_item_prefix = \"Job Readiness\"\n",
        "cognitive_item_prefix = \"Cognitive\"\n",
        "interview_item_prefix = \"Interview\"\n",
        "resume_item_prefix = \"Resume\"\n",
        "\n",
        "# LLM Prompts\n",
        "job_readiness_question_prefix = \"Rate your familarity with the following work-related tools or processes (1 = Not Familiar; 3 = Moderately Familiar; 5 = Very Familiar) with the following technology or system: \"\n",
        "personality_likert_question_strip  = \"Describe yourself as you generally are now, not as you wish to be in the future. Describe yourself as you honestly see yourself, in relation to other people you know of the same sex as you are, and roughly your same age. So that you can describe yourself in an honest manner, your responses will be kept in absolute confidence. Indicate for each statement whether it is 1. Very Inaccurate, 2. Moderately Inaccurate, 3. Neither Accurate Nor Inaccurate, 4. Moderately Accurate, or 5. Very Accurate as a description of you. \"\n",
        "personality_likert_question_prefix = \"Indicate for each statement whether it is 1. Very Inaccurate, 2. Moderately Inaccurate, 3. Neither Accurate Nor Inaccurate, 4. Moderately Accurate, or 5. Very Accurate as a description of you. \"\n",
        "personality_choice_question_prefix = \"Indicate on a -2 to +2 scale (-2 = Option A is more me; -1 = Option A is slightly more me; 0 = Both describe me Equally; 1 = Option B is slightly more me; 2 = Option B is more me), which better describes you: \"\n",
        "\n",
        "job_readiness_system_prompt = \"\"\"You are applying for a {0}position of {1}, in the {2} department, at a {3}.\n",
        "\n",
        "Select only the skills, processes, technology, or systems, from the provided list, that are required for the position.\n",
        "\n",
        "Follow these rules when responding:\n",
        "- Include all technical skills provided\n",
        "- Do not correct spelling mistakes or remove extra spaces from the provided job skills, processes, technology, or systems\n",
        "- Respond with a semicolon-separated list\n",
        "\"\"\"\n",
        "\n",
        "interview_system_prompt = \"\"\"You are applying for a job at a large-sized company, and you need to respond with the best answer to the situational judgement question so that you are hired for the position.\n",
        "\n",
        "Follow these rules when responding:\n",
        "- Respond with less than 750 characters\n",
        "- Respond on a single line\n",
        "- Respond as a job candidate with high integrity, tolerance for ambiguity, and has leadership skills\n",
        "- Respond as a job candidate who is honest and truthful\n",
        "- Respond as a job candidate who is optimistic, ambitious, and enthusiastic\n",
        "- Respond as a job candidate who is compassionate, considerate, confident, positive, articulate, flexible, professional, self-aware, empathic, self-driven, motivated, persistent, resilient, interested, attentive, well-prepared, ethical, warm, gregarious, imaginative, adaptable, principled, and composed\n",
        "\"\"\"\n",
        "\n",
        "personality_choice_system_prompt = \"\"\"You are applying for a job and you need to respond with the best personality choice so that you are hired.\n",
        "\n",
        "Follow these rules when responding:\n",
        "- Respond with an integer between -2 and 2\n",
        "- Respond as someone with high integrity, tolerance for ambiguity, leadership skills, optimistic, compassionate, considerate, honest, ambitious, enthusiastic\n",
        "\"\"\"\n",
        "\n",
        "personality_likert_system_prompt = \"\"\"You are applying for a job and you need to respond with the best personality answer so that you are hired.\n",
        "\n",
        "Follow these rules when responding:\n",
        "- Only respond with a number between 1 and 5\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "eeoiFx8feqFs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions: Helper"
      ],
      "metadata": {
        "id": "JECp3DljochJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_mangagement_level(job):\n",
        "  result = \"\"\n",
        "  job = job.lower()\n",
        "\n",
        "  if ('lead' in job or\n",
        "      'manager' in job or\n",
        "      'coordinator' in job or\n",
        "      'supervisor' in job):\n",
        "    result = \"low-level management\"\n",
        "  elif ('director' in job or\n",
        "        'senior' in job):\n",
        "    result = \"mid-level management\"\n",
        "  elif ('chief' in job or\n",
        "        'vp' in job or\n",
        "        'officer' in job):\n",
        "    result = \"upper-level management\"\n",
        "\n",
        "  return result\n",
        "\n",
        "def gen_company_size(employee_count):\n",
        "  result = \"\"\n",
        "  employee_count = int(employee_count.replace(\",\", \"\"))\n",
        "\n",
        "  if (employee_count < 100):\n",
        "    result = \"small-sized company\"\n",
        "  elif (employee_count > 100 and employee_count < 1000):\n",
        "    result = \"mid-sized company\"\n",
        "  elif (employee_count > 1000):\n",
        "    result = \"large-sized company\"\n",
        "\n",
        "  return result\n",
        "\n",
        "def validate_submission(df):\n",
        "  for i, r in df.iterrows():\n",
        "    response_format = r.Format.strip().lower()\n",
        "    response = str(r.Response).strip().lower()\n",
        "\n",
        "    if (len(response)<1 or response==\"nan\"):\n",
        "      raise ValueError(f\"Row {i}: Missing response, '{r.Response}'\")\n",
        "\n",
        "    if (response_format == \"text (max 3000 characters)\"):\n",
        "      if (len(response) > 3000):\n",
        "        print(f\"Row {i}: Warning, response longer than 3000 chars, length={len(response)}\")\n",
        "\n",
        "    if (response_format == \"text (max 750 characters)\"):\n",
        "      if (len(response) > 750):\n",
        "        print(f\"Row {i}: Warning, response longer than 750 chars, length={len(response)}\")\n",
        "\n",
        "    if (response_format == \"text  (max 20 characters)\"):\n",
        "      if (len(response) > 20):\n",
        "        print(f\"Row {i}: Warning, response longer than 20 chars, length={len(response)}\")\n",
        "\n",
        "    if (response_format == \"integer\"):\n",
        "      try:\n",
        "        convert_to_int = float(response)\n",
        "      except ValueError as e:\n",
        "        print(f\"Id {i}: {e}\")\n",
        "        raise Exception(e)\n",
        "\n",
        "    if (response_format == \"integer (1 to 5)\"):\n",
        "      try:\n",
        "        convert_to_int = int(response)\n",
        "\n",
        "        if convert_to_int < 1 or convert_to_int > 5:\n",
        "          raise ValueError(f\"Row {i}: Outside 1 to 5 range, '{r.Response}'\")\n",
        "      except ValueError as e:\n",
        "        print(f\"Id {i}: {e}\")\n",
        "        raise Exception(e)\n",
        "\n",
        "    if (response_format == \"integer (-2 to 2)\"):\n",
        "      try:\n",
        "        convert_to_int = int(response)\n",
        "\n",
        "        if convert_to_int < -2 or convert_to_int > 2:\n",
        "          raise ValueError(f\"Row {i}: Outside -1 to 2 range, '{r.Response}'\")\n",
        "      except ValueError as e:\n",
        "        print(f\"Id {i}: {e}\")\n",
        "        raise Exception(e)"
      ],
      "metadata": {
        "id": "rzA1S7G_oegj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions: OpenAI API"
      ],
      "metadata": {
        "id": "YIaDk9oEe_u9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def llm_api(model, messages, **kwargs):\n",
        "\n",
        "  if len(model)==0:\n",
        "      raise ValueError(f\"Model cannot be empty: {model}\")\n",
        "\n",
        "  if len(messages)==0:\n",
        "      raise ValueError(f\"User prompt cannot be empty: {messages}\")\n",
        "\n",
        "  max_completion_tokens = 1000\n",
        "  if \"max_completion_tokens\" in kwargs:\n",
        "    max_completion_tokens = kwargs[\"max_completion_tokens\"]\n",
        "\n",
        "  reasoning_effort = \"medium\"\n",
        "  if \"reasoning_effort\" in kwargs:\n",
        "    reasoning_effort = kwargs[\"reasoning_effort\"]\n",
        "\n",
        "  model_params = {}\n",
        "\n",
        "  if (model == openai_llm_gpt_4o_mini or\n",
        "      model == openai_llm_gpt_4o or\n",
        "      model == openai_llm_gpt_45):\n",
        "    model_params = {\n",
        "        \"model\": model,\n",
        "        \"temperature\": 0,\n",
        "        \"max_completion_tokens\": max_completion_tokens,\n",
        "        \"messages\": messages,\n",
        "        \"top_p\": 1,\n",
        "        \"frequency_penalty\": 0,\n",
        "        \"presence_penalty\": 0,\n",
        "        \"seed\": 42\n",
        "    }\n",
        "  elif model == openai_llm_gpt_o3_mini:\n",
        "    model_params = {\n",
        "        \"model\": model,\n",
        "        \"max_completion_tokens\": max_completion_tokens,\n",
        "        \"reasoning_effort\": reasoning_effort,\n",
        "        \"messages\": messages,\n",
        "        \"top_p\": 1,\n",
        "        \"frequency_penalty\": 0,\n",
        "        \"presence_penalty\": 0,\n",
        "        \"seed\": 42\n",
        "    }\n",
        "  else:\n",
        "    raise ValueError(f\"Unsupported model in llm_api() function: {model}\")\n",
        "\n",
        "\n",
        "  start_time = time.time()\n",
        "  completion = openai_client.chat.completions.create(**model_params)\n",
        "  end_time = time.time()\n",
        "\n",
        "  response = completion.choices[0].message\n",
        "  result = response.content\n",
        "  duration = round(end_time - start_time, 1)\n",
        "  prompt = \"\\n\".join(str(item) for item in messages)\n",
        "\n",
        "  #print(f\"Open AI Response={completion}\")\n",
        "\n",
        "  return (result, duration, prompt)"
      ],
      "metadata": {
        "id": "DtFAWPgKfBCN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions: Personality Likert"
      ],
      "metadata": {
        "id": "hETXXqRX77Hq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def personality_likert_llm(r):\n",
        "  formatted_system_prompt = personality_likert_system_prompt + \"\\n\\n\" + personality_likert_question_prefix\n",
        "\n",
        "  user_prompt = r.Question.replace(personality_likert_question_strip, \"\").strip()\n",
        "\n",
        "  messages = [{\n",
        "    \"role\": \"system\",\n",
        "    \"content\": f\"{formatted_system_prompt}\"\n",
        "  },\n",
        "  {\n",
        "    \"role\": \"user\",\n",
        "    \"content\": f\"{user_prompt}\"\n",
        "  }]\n",
        "\n",
        "  (answer, duration, prompt) = llm_api(openai_llm_gpt_4o_mini, messages)\n",
        "\n",
        "  return (answer, duration, prompt)\n",
        "\n",
        "def personality_likert_rating(r):\n",
        "  question = r.Question\n",
        "\n",
        "  personality_likert_slice = df_personality_likert_answers[(df_personality_likert_answers[question_col].str.lower() == question.lower())].iloc[0]\n",
        "\n",
        "  rating = personality_likert_slice[response_col]\n",
        "  duration = personality_likert_slice[duration_col]\n",
        "  prompt = personality_likert_slice[prompt_col]\n",
        "\n",
        "  return (rating, duration, prompt)"
      ],
      "metadata": {
        "id": "SrjvDlvz791G"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions: Personality Choice"
      ],
      "metadata": {
        "id": "FnuN2MltGeOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def personality_choice_llm(r, messages):\n",
        "\n",
        "  (answer, duration, prompt) = llm_api(openai_llm_gpt_o3_mini, messages, reasoning_effort=\"low\")\n",
        "\n",
        "  return (answer, duration, prompt)\n",
        "\n",
        "def personality_choice_rating(r):\n",
        "  question = r.Question\n",
        "\n",
        "  personality_choice_slice = df_personality_choice_answers[(df_personality_choice_answers[question_col].str.lower() == question.lower())].iloc[0]\n",
        "\n",
        "  rating = personality_choice_slice[response_col]\n",
        "  duration = personality_choice_slice[duration_col]\n",
        "  prompt = personality_choice_slice[prompt_col]\n",
        "\n",
        "  if (len(str(rating))<1 or str(rating)==\"nan\"):\n",
        "    rating = 0\n",
        "\n",
        "  return (rating, duration, prompt)"
      ],
      "metadata": {
        "id": "R5L9xqRAGfUT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions: Job Readiness"
      ],
      "metadata": {
        "id": "04lihDUOP5Sv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def skills_job_readiness_llm(r):\n",
        "  formatted_system_prompt = job_readiness_system_prompt.format(\n",
        "    r.ManagementLevel.strip(),\n",
        "    r.Job.strip(),\n",
        "    r.Department.strip(),\n",
        "    r.CompanySize.strip()\n",
        "  )\n",
        "\n",
        "  user_prompt = r.AllSkills\n",
        "\n",
        "  messages = [{\n",
        "    \"role\": \"system\",\n",
        "    \"content\": f\"{formatted_system_prompt}\"\n",
        "  },\n",
        "  {\n",
        "    \"role\": \"user\",\n",
        "    \"content\": f\"{user_prompt}\"\n",
        "  }]\n",
        "\n",
        "  (answer, duration, prompt) = llm_api(openai_llm_gpt_4o, messages)\n",
        "\n",
        "  return (answer, duration, prompt)\n",
        "\n",
        "def skills_job_readiness_rating(r):\n",
        "  job = r.Job\n",
        "  current_skill   = r.Question.replace(job_readiness_question_prefix, \"\").strip().lower()\n",
        "\n",
        "  job_skills_slice = df_job_skills_answers[(df_job_skills_answers[job_title_col].str.lower() == job.lower())].iloc[0]\n",
        "\n",
        "  all_skills_csv = job_skills_slice[skills_col]\n",
        "  duration = job_skills_slice[duration_col]\n",
        "\n",
        "  rating = 5\n",
        "\n",
        "  if any(current_skill.startswith(e) for e in excluded_skills_starts_with):\n",
        "    rating = 1\n",
        "\n",
        "  return (rating, duration, all_skills_csv)"
      ],
      "metadata": {
        "id": "ufoPOx1UP8Rv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions: Resume and Interview"
      ],
      "metadata": {
        "id": "b6T-YI5mspJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def skills_resume_text(r):\n",
        "  duration = 0.0\n",
        "\n",
        "  job = r.Job\n",
        "  job_skills_slice = df_job_skills_answers[(df_job_skills_answers[job_title_col].str.lower() == job.lower())].iloc[0]\n",
        "\n",
        "  job_skills_csv = job_skills_slice[skills_col].strip()\n",
        "  job_skills = [s.strip() for s in job_skills_csv.split(\";\") if s.strip()]\n",
        "\n",
        "  included_job_skills = [s for s in job_skills if all(not s.startswith(e) for e in excluded_skills_starts_with)]\n",
        "  included_job_skills_csv = \"; \".join(included_job_skills)\n",
        "\n",
        "  resume = f\"\"\"Peter Parker\n",
        "Contact Information:\n",
        "Phone: (123) 456-7890\n",
        "Email: pparker@work.com\n",
        "LinkedIn: linkedin.com/in/pparker\n",
        "\n",
        "Skills:\n",
        "{included_job_skills_csv}\n",
        "\"\"\"\n",
        "\n",
        "  resume = resume[:3000]\n",
        "\n",
        "  return (resume, duration, included_job_skills_csv)\n",
        "\n",
        "def skills_interview_llm(r):\n",
        "  formatted_system_prompt = interview_system_prompt\n",
        "\n",
        "  user_prompt = r.Question.strip()\n",
        "\n",
        "  messages = [{\n",
        "    \"role\": \"system\",\n",
        "    \"content\": f\"{formatted_system_prompt}\"\n",
        "  },\n",
        "  {\n",
        "    \"role\": \"user\",\n",
        "    \"content\": f\"{user_prompt}\"\n",
        "  }]\n",
        "\n",
        "  (answer, duration, prompt) = llm_api(openai_llm_gpt_o3_mini, messages, max_completion_tokens=2000, reasoning_effort=\"low\")\n",
        "\n",
        "  return (answer, duration, prompt)\n",
        "\n",
        "def skills_interview_text(r):\n",
        "  question = r.Question\n",
        "\n",
        "  interview_slice = df_interview_answers[(df_interview_answers[question_col].str.lower() == question.lower())].iloc[0]\n",
        "\n",
        "  response = interview_slice[response_col]\n",
        "  prompt   = interview_slice[prompt_col]\n",
        "  duration = interview_slice[duration_col]\n",
        "\n",
        "  return (response, duration, prompt)"
      ],
      "metadata": {
        "id": "GcjyqVItsr4e"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions: Numeric Operations Solver"
      ],
      "metadata": {
        "id": "gXD-CTVOSaWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cognitive_numeric_ops(question):\n",
        "  enable_debug = False\n",
        "\n",
        "  duration = 0.0\n",
        "\n",
        "  primes = {2, 3, 5, 7}\n",
        "\n",
        "  add_div_by_3   = \"Add all digits that are divisible by 3 to your running total.\"\n",
        "  add_even       = \"Add all even digits to your running total.\"\n",
        "  add_count_gt_5 = \"Add the count of digits greater than 5 to your running total.\"\n",
        "  add_second_largest_unique = \"Add the second largest unique digit in the list to your running total.\"\n",
        "  add_sum_of_squares_even_0based = \"Add the sum of squares of digits at even indices (0-based) to your running total.\"\n",
        "  add_sum_of_prime = \"Add the sum of the digits that are prime numbers (2, 3, 5, 7) to your running total.\"\n",
        "  cond_even_odd_mult2_add5 = \"If there are more even digits than odd digits, multiply your total by 2. Otherwise, add 5.\"\n",
        "  multiply_by_1_plus_count7 = \"Multiply your running total by (1 plus the count of digit '7' in the sequence).\"\n",
        "  multiply_by_prod_prime_pos = \"Multiply your running total by the product of digits in prime positions.\"\n",
        "  minus_odd       = \"Subtract all odd digits from your running total.\"\n",
        "  minus_floor_avg = \"Subtract the floor of the average of all digits from your running total.\"\n",
        "  minus_sum_odd_pos = \"Subtract the sum of the digits in odd positions (1-based) from your running total.\"\n",
        "\n",
        "  sequence_re = re.compile(r'((\\d\\s)+\\d)', flags=re.IGNORECASE)\n",
        "  all_steps_re = re.compile(r'Step \\d\\:.*', flags=re.IGNORECASE)\n",
        "  strip_step_prefix = re.compile(r'Step\\s*\\d\\:\\s*', flags=re.IGNORECASE)\n",
        "\n",
        "  try:\n",
        "      sequence = re.search(sequence_re, question)\n",
        "      digits = []\n",
        "\n",
        "      if sequence:\n",
        "          sequence = sequence.group()\n",
        "          digits = [int(d.strip()) for d in sequence.split()]\n",
        "      else:\n",
        "          print(f\"Cannot find sequence: {question}\")\n",
        "\n",
        "\n",
        "      steps = re.findall(all_steps_re, question)\n",
        "\n",
        "      #print(f\"{q}: {steps}\")\n",
        "\n",
        "      steps = [re.sub(strip_step_prefix, \"\", s) for s in steps]\n",
        "\n",
        "      total = 0\n",
        "\n",
        "      for i, s in enumerate(steps):\n",
        "          if s.lower() == add_div_by_3.lower():\n",
        "              temp = sum(d for d in digits if d % 3 == 0)\n",
        "              if enable_debug: print(f\"Step {i+1}: add_div_by_3 = {total} + {temp}\")\n",
        "              total += temp\n",
        "\n",
        "          elif s.lower() == add_even.lower():\n",
        "              temp = sum(d for d in digits if d % 2 == 0)\n",
        "              if enable_debug: print(f\"Step {i+1}: add_even = {total} + {temp}\")\n",
        "              total += temp\n",
        "\n",
        "          elif s.lower() == add_count_gt_5.lower():\n",
        "              temp = sum(1 for d in digits if d > 5)\n",
        "              if enable_debug: print(f\"Step {i+1}: add_count_gt_5 = {total} + {temp}\")\n",
        "              total += temp\n",
        "\n",
        "          elif s.lower() == add_second_largest_unique.lower():\n",
        "              temp = 0\n",
        "              unique_digits = sorted(set(digits), reverse=True)\n",
        "              if enable_debug: print(f\"unique_digits: {unique_digits}\")\n",
        "              if len(unique_digits) > 1:\n",
        "                  temp = unique_digits[1]\n",
        "\n",
        "              if enable_debug: print(f\"Step {i+1}: add_second_largest_unique = {total} + {temp}\")\n",
        "              total += temp\n",
        "\n",
        "          elif s.lower() == add_sum_of_squares_even_0based.lower(): # 0-based means sequence index starts at 0\n",
        "              temp = sum(digits[i]**2 for i in range(0, len(digits), 2))\n",
        "              if enable_debug: print(f\"Step {i+1}: add_sum_of_squares_even_0based = {total} + {temp}\")\n",
        "              total += temp\n",
        "\n",
        "          elif s.lower() == add_sum_of_prime.lower():\n",
        "              temp = sum(d for d in digits if d in primes)\n",
        "              if enable_debug: print(f\"Step {i+1}: add_sum_of_prime = {total} + {temp}\")\n",
        "              total += temp\n",
        "\n",
        "          elif s.lower() == cond_even_odd_mult2_add5.lower():\n",
        "              evens = sum(1 for d in digits if d % 2 == 0)\n",
        "              odds = len(digits) - evens\n",
        "              if evens > odds:\n",
        "                  if enable_debug: print(f\"Step {i+1}: cond_even_odd_mult2_add5 = {total} * 2\")\n",
        "                  total *= 2\n",
        "              else:\n",
        "                  if enable_debug: print(f\"Step {i+1}: cond_even_odd_mult2_add5 = {total} + 5\")\n",
        "                  total += 5\n",
        "\n",
        "          elif s.lower() == multiply_by_1_plus_count7.lower():\n",
        "              temp = 1 + digits.count(7)\n",
        "              if enable_debug: print(f\"Step {i+1}: multiply_by_1_plus_count7 = {total} * {temp}\")\n",
        "              total *= temp\n",
        "\n",
        "          elif s.lower() == multiply_by_prod_prime_pos.lower(): # 0-based\n",
        "              prime_pos_digits = [digits[i] for i in primes]\n",
        "\n",
        "              temp = 1\n",
        "              for d in prime_pos_digits:\n",
        "                  temp *= d\n",
        "\n",
        "              if enable_debug: print(f\"Step {i+1}: multiply_by_prod_prime_pos = {total} * {temp}\")\n",
        "              total *= temp\n",
        "\n",
        "          elif s.lower() == minus_odd.lower():\n",
        "              temp = sum(d for d in digits if d % 2 != 0)\n",
        "              if enable_debug: print(f\"Step {i+1}: minus_odd = {total} - {temp}\")\n",
        "              total -= temp\n",
        "\n",
        "          elif s.lower() == minus_floor_avg.lower():\n",
        "              temp = int(np.floor(np.mean(digits)))\n",
        "              if enable_debug: print(f\"Step {i+1}: minus_floor_avg = {total} - {temp}\")\n",
        "              total -= temp\n",
        "\n",
        "          elif s.lower() == minus_sum_odd_pos.lower(): # 1-based means sequence index starts at 1\n",
        "              temp = sum(digits[i] for i in range(len(digits)) if i % 2 == 0)\n",
        "              if enable_debug: print(f\"Step {i+1}: minus_sum_odd_pos = {total} - {temp}\")\n",
        "              total -= temp\n",
        "\n",
        "          else:\n",
        "              raise ValueError(f\"Unsupported step {i+1}: {question}\\n{s}\")\n",
        "\n",
        "      result = total\n",
        "  except Exception as e:\n",
        "    print(f\"{question}: {e}\")\n",
        "    raise Exception(e)\n",
        "\n",
        "  return (result, duration, \"\\n\".join(steps))"
      ],
      "metadata": {
        "id": "EGhfg5xhTHgv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions: Next Number Solver"
      ],
      "metadata": {
        "id": "-LIFq3Cx8Wex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cognitive_next_number(question):\n",
        "  enable_debug = False\n",
        "\n",
        "  duration = 0.0\n",
        "\n",
        "  try:\n",
        "      ## Parse the question to extract sequence of numbers\n",
        "      sequence = question.split('?')[1].strip()\n",
        "\n",
        "      numbers = [int(num) for num in sequence.split(',') if num.strip()]\n",
        "\n",
        "      if(len(numbers) < 4):\n",
        "          print(f\"Too short, likely a parsing error: {sequence} != {numbers}\")\n",
        "\n",
        "      result = None\n",
        "      math_type = None\n",
        "\n",
        "      if not result:\n",
        "          ## Check for Arithmetic Sequence (consistent differences between elements)\n",
        "          diffs = [numbers[i+1] - numbers[i] for i in range(len(numbers)-1)]\n",
        "\n",
        "          if enable_debug: print(f\"{numbers}; {diffs}\")\n",
        "\n",
        "          if (len(diffs) > 2\n",
        "              and all(d == diffs[0] for d in diffs)):\n",
        "              result = numbers[-1] + diffs[0]\n",
        "\n",
        "              math_type = \"Arithmetic Sequence\"\n",
        "\n",
        "              if enable_debug: print(f\"Arithmetic Sequence, {numbers}; {diffs}; {result}\")\n",
        "\n",
        "      if not result:\n",
        "          ## Check for Alternating Arithmetic Sequence\n",
        "          evens = [numbers[i] for i in range(len(numbers)) if i % 2 == 0]\n",
        "          odds  = [numbers[i] for i in range(len(numbers)) if i % 2 != 0]\n",
        "\n",
        "          even_diffs = [evens[i+1] - evens[i] for i in range(len(evens)-1)]\n",
        "          odd_diffs  = [odds[i+1]  - odds[i]  for i in range(len(odds)-1)]\n",
        "\n",
        "          if enable_debug: print(f\"{numbers}; {evens}; {even_diffs}; {odds}; {odd_diffs};\")\n",
        "\n",
        "          if ((len(even_diffs) > 1)\n",
        "              and (len(odd_diffs) > 1)\n",
        "              and all(d == even_diffs[0] for d in even_diffs)\n",
        "              and all(d == odd_diffs[0]  for d in odd_diffs)):\n",
        "\n",
        "              is_even_len = (len(numbers) % 2 == 0)\n",
        "\n",
        "              if is_even_len:\n",
        "                  result = numbers[-2] + even_diffs[0]\n",
        "              else:\n",
        "                  result = numbers[-2] + odd_diffs[0]\n",
        "\n",
        "              math_type = \"Alt Arithmetic Sequence\"\n",
        "\n",
        "              if enable_debug: print(f\"Alternating Arithmetic Sequence, {numbers}; {evens}; {even_diffs}; {odds}; {odd_diffs}; {result}\")\n",
        "\n",
        "      if not result:\n",
        "          ## Fibonacci sequence (add previous term)\n",
        "          is_sum_of_previous = all((numbers[i] + numbers[i-1])== numbers[i+1] for i in range(1, len(numbers)-1))\n",
        "\n",
        "          if is_sum_of_previous:\n",
        "              result = numbers[-1] + numbers[-2]\n",
        "              result = numbers[-1] + result # 2nd next number\n",
        "\n",
        "              if enable_debug: print(f\"Fibonacci Sequence, {sequence}: {is_sum_of_previous}\")\n",
        "\n",
        "              math_type = \"Fibonacci Sequence\"\n",
        "\n",
        "      if not result:\n",
        "          if all(n != 0 for n in numbers):\n",
        "              ## Check for Geometric Sequence (consistent ratios between non-zero elements)\n",
        "              ratios = [numbers[i+1] / numbers[i] for i in range(len(numbers)-1)]\n",
        "\n",
        "              if enable_debug: print(f\"{numbers}; {ratios}\")\n",
        "\n",
        "              if (len(ratios) > 2\n",
        "                  and all(r == ratios[0] for r in ratios)):\n",
        "\n",
        "                  result = numbers[-1] * ratios[0]\n",
        "\n",
        "                  if len(numbers) < 5:\n",
        "                    result = result * ratios[0] # 2nd next number\n",
        "\n",
        "                  if enable_debug: print(f\"Geometric Sequence, {numbers}; {ratios}; {result}\")\n",
        "\n",
        "                  math_type = \"Geometric Sequence\"\n",
        "\n",
        "      if not result:\n",
        "          ## Check for Geometric Sequence amoung differences (consistent ratios between differences)\n",
        "          diffs = [numbers[i+1] - numbers[i] for i in range(len(numbers)-1)]\n",
        "\n",
        "          ratios = [diffs[i+1] / diffs[i] for i in range(len(diffs)-1)]\n",
        "\n",
        "          if enable_debug: print(f\"{diffs}: {ratios}\")\n",
        "\n",
        "          if (len(ratios) > 0\n",
        "              and all(r == ratios[0] for r in ratios)):\n",
        "\n",
        "              result = numbers[-1] + (diffs[-1] * ratios[0])\n",
        "\n",
        "              if enable_debug: print(f\"Diff Geometric Sequence, {numbers}; {ratios}; {result}\")\n",
        "\n",
        "              math_type = \"Diff Geometric Sequence\"\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"{question}: {e}\")\n",
        "    raise Exception(e)\n",
        "\n",
        "  return (result, duration, math_type)"
      ],
      "metadata": {
        "id": "suykgCXa8bNV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions: Unscramble Solver"
      ],
      "metadata": {
        "id": "sChxKoVHWElK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_letters(phrase):\n",
        "  letter = list(phrase.replace(\" \", \"\").lower())\n",
        "\n",
        "  letter.sort()\n",
        "\n",
        "  result = \"\".join(letter)\n",
        "\n",
        "  return result\n",
        "\n",
        "def cognitive_unscramble(question):\n",
        "  enable_debug = False\n",
        "\n",
        "  answer = \"\"\n",
        "  duration = 0.0\n",
        "  prompt = \"\"\n",
        "\n",
        "  scrambled_phrase = question.split(':')[1].strip()\n",
        "\n",
        "  sorted_letters = sort_letters(scrambled_phrase)\n",
        "\n",
        "  if enable_debug: print(f\"{scrambled_phrase}, {sorted_letters}\")\n",
        "\n",
        "  if sorted_letters in unscramble_dict['Phrase']:\n",
        "    answer = unscramble_dict['Phrase'][sorted_letters]\n",
        "    prompt = sorted_letters\n",
        "  else:\n",
        "    print(f\"(Not found in unscramble dictionary: orig={scrambled_phrase}, sorted={sorted_letters})\")\n",
        "    user_prompt = question.strip()\n",
        "\n",
        "    user_prompt += \"\\n\\nOnly respond with the answer.\"\n",
        "\n",
        "    messages = [{\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"{user_prompt}\"\n",
        "    }]\n",
        "\n",
        "    (answer, duration, prompt) = llm_api(openai_llm_gpt_45, messages)\n",
        "\n",
        "    answer = answer.strip().lower()\n",
        "\n",
        "    # Add answer to dictionary\n",
        "    if answer.strip():\n",
        "      unscramble_dict['Phrase'][sorted_letters] = answer\n",
        "    else:\n",
        "      print(f\"Empty response from LLM: orig={scrambled_phrase}\")\n",
        "\n",
        "  return (answer, duration, prompt)"
      ],
      "metadata": {
        "id": "JeNYvR9IWGhG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions: Job Application"
      ],
      "metadata": {
        "id": "SMzztO__-NWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_job_application(r):\n",
        "  question = r.Question.strip()\n",
        "  question_item_type = r.Item.strip()\n",
        "  question_format = r.Format.strip()\n",
        "\n",
        "  answer = \"\"\n",
        "  duration = 0.0\n",
        "  prompt = \"\"\n",
        "\n",
        "  if (question_item_type.lower().startswith(resume_item_prefix.lower())):\n",
        "\n",
        "     (answer, duration, prompt) = skills_resume_text(r)\n",
        "\n",
        "  elif (question_item_type.lower().startswith(interview_item_prefix.lower())):\n",
        "\n",
        "     (answer, duration, prompt) = skills_interview_text(r)\n",
        "\n",
        "  elif (question_item_type.lower().startswith(cognitive_item_prefix.lower())\n",
        "        and question_format.lower().startswith(\"Integer\".lower())\n",
        "        and question.lower().startswith(\"Below is a random sequence of digits:\".lower())):\n",
        "\n",
        "     (answer, duration, prompt) = cognitive_numeric_ops(question)\n",
        "\n",
        "  elif (question_item_type.lower().startswith(cognitive_item_prefix.lower())\n",
        "        and question_format.lower().startswith(\"Integer\".lower())\n",
        "        and question.lower().startswith(\"What is the next number?\".lower())):\n",
        "\n",
        "     (answer, duration, prompt) = cognitive_next_number(question)\n",
        "\n",
        "  elif (question_item_type.lower().startswith(cognitive_item_prefix.lower())\n",
        "        and question_format.lower().startswith(\"Text\".lower())):\n",
        "\n",
        "     (answer, duration, prompt) = cognitive_unscramble(question)\n",
        "\n",
        "  elif (question_item_type.lower().startswith(personality_likert_item_prefix.lower())):\n",
        "\n",
        "    (answer, duration, prompt) = personality_likert_rating(r)\n",
        "\n",
        "  elif (question_item_type.lower().startswith(personality_choice_item_prefix.lower())):\n",
        "\n",
        "    (answer, duration, prompt) = personality_choice_rating(r)\n",
        "\n",
        "  elif (question_item_type.lower().startswith(job_readiness_item_prefix.lower())):\n",
        "\n",
        "    (answer, duration, prompt) = skills_job_readiness_rating(r)\n",
        "\n",
        "  else:\n",
        "\n",
        "    raise ValueError(f\"Unsupported question type: {question_item_type}\")\n",
        "\n",
        "  return (answer, duration, prompt)"
      ],
      "metadata": {
        "id": "AV3TSLFN-T8d"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing: Merge Raw Datasets"
      ],
      "metadata": {
        "id": "NrlXrB97pQ1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Merge raw data datasets...\")\n",
        "\n",
        "# Load Job Listing Dataset\n",
        "df_job_listings = pd.read_excel(job_listings_path, dtype=str)\n",
        "\n",
        "# Generate Management Level\n",
        "df_job_listings[management_col] = df_job_listings[role_title_col].apply(lambda j: gen_mangagement_level(j))\n",
        "\n",
        "# Generate Company Size\n",
        "df_job_listings[company_size_col] = df_job_listings[employee_count_col].apply(lambda e: gen_company_size(e))\n",
        "\n",
        "# Load Job Application Dataset\n",
        "df_job_applications = pd.read_excel(job_applications_path, dtype=str)\n",
        "\n",
        "# Merge Job Datasets\n",
        "df_combined = pd.merge(df_job_applications, df_job_listings, left_on=job_title_col, right_on=role_title_col, how='left')\n",
        "df_combined.drop(columns=[role_title_col], axis=1, inplace=True)\n",
        "df_combined.index = df_combined.index + 1\n",
        "df_combined.rename_axis(id_col, inplace=True)\n",
        "#df_combined.to_excel(combined_path)\n",
        "\n",
        "print(\"Completed.\")"
      ],
      "metadata": {
        "id": "ZGPWgiY7pXcF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73f52c48-4bcd-4459-8c31-1209358c85fe"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merge raw data datasets...\n",
            "Completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing: Skills by Job"
      ],
      "metadata": {
        "id": "DtDqiMMHvftf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Process skills by job...\")\n",
        "\n",
        "# Extract Job Readiness Questions\n",
        "df_job_all_skills = df_combined[(df_combined[item_col].str.startswith(job_readiness_item_prefix))].copy()\n",
        "\n",
        "# Extract Job Readiness skill (strip out question)\n",
        "df_job_all_skills[question_col] = df_job_all_skills[question_col].str.replace(job_readiness_question_prefix, \"\")\n",
        "df_job_all_skills[question_col] = df_job_all_skills[question_col].str.strip()\n",
        "\n",
        "# Join all skills as csv per job\n",
        "df_job_all_skills[skills_col] = df_job_all_skills.groupby([job_title_col])[question_col].transform(lambda x: '; '.join(x))\n",
        "\n",
        "# Extract unique job skills\n",
        "df_job_skills_unique = df_job_all_skills.groupby([question_col])[question_col].count().reset_index(name=count_col)\n",
        "\n",
        "df_job_skills_unique.to_excel(job_skills_unique_path, index=False)\n",
        "\n",
        "# Keep only unique jobs\n",
        "df_job_skills = df_job_all_skills[job_info_cols].copy()\n",
        "df_job_skills.drop_duplicates(inplace=True)\n",
        "df_job_skills.reset_index(drop=True, inplace=True)\n",
        "df_job_skills.index = df_job_skills.index + 1\n",
        "df_job_skills.rename_axis(id_col, inplace=True)\n",
        "\n",
        "df_job_skills.to_excel(job_skills_path)\n",
        "\n",
        "df_job_skills_answers = df_job_skills.copy()\n",
        "df_job_skills_answers[response_col] = \"\"\n",
        "df_job_skills_answers[duration_col] = \"\"\n",
        "df_job_skills_answers[prompt_col] = \"\"\n",
        "\n",
        "if os.path.isfile(job_skills_answers_path):\n",
        "  df_job_skills_answers = pd.read_excel(job_skills_answers_path, index_col=0)\n",
        "\n",
        "print(f\"Start Processing: \", datetime.now())\n",
        "print(\"Progress: \", end=\"\")\n",
        "for i, r in df_job_skills_answers.iterrows():\n",
        "  if i%10 == 0:\n",
        "      print(\".\", end=\"\")\n",
        "\n",
        "  response = str(r.Response).strip().lower()\n",
        "\n",
        "  if (len(response)<1 or response==\"nan\"):\n",
        "    (answer, duration, prompt) = skills_job_readiness_llm(r)\n",
        "\n",
        "    df_job_skills_answers.loc[df_job_skills_answers.index == i, [response_col]] = answer\n",
        "    df_job_skills_answers.loc[df_job_skills_answers.index == i, [duration_col]] = duration\n",
        "    df_job_skills_answers.loc[df_job_skills_answers.index == i, [prompt_col]] = prompt\n",
        "\n",
        "    if i>0 and i%50==0:\n",
        "        print(\"\\nSaving Progress: \", i, datetime.now())\n",
        "        df_job_skills_answers.to_excel(job_skills_answers_path)\n",
        "\n",
        "print(f\"\\nEnd Processing: \", datetime.now())\n",
        "df_job_skills_answers.to_excel(job_skills_answers_path)\n",
        "\n",
        "print(\"Completed.\")"
      ],
      "metadata": {
        "id": "SvROhLrnvkra",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fce488e-8291-4ec5-a240-19b8c6753d33"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process skills by job...\n",
            "Start Processing:  2025-04-10 22:23:52.307323\n",
            "Progress: \n",
            "End Processing:  2025-04-10 22:23:58.157110\n",
            "Completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing: Interview Questions"
      ],
      "metadata": {
        "id": "qf2EgR4v-P0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Process interview questions...\")\n",
        "\n",
        "# Extract Interview Questions\n",
        "df_interview = df_combined[(df_combined[item_col].str.startswith(interview_item_prefix))].copy()\n",
        "\n",
        "# Keep only unique cases\n",
        "df_interview = df_interview[[question_col]].copy()\n",
        "df_interview.drop_duplicates(inplace=True)\n",
        "df_interview.reset_index(drop=True, inplace=True)\n",
        "df_interview.index = df_interview.index + 1\n",
        "df_interview.rename_axis(id_col, inplace=True)\n",
        "\n",
        "df_interview.to_excel(interview_path)\n",
        "\n",
        "df_interview_answers = df_interview.copy()\n",
        "df_interview_answers[response_col] = \"\"\n",
        "df_interview_answers[duration_col] = \"\"\n",
        "df_interview_answers[prompt_col] = \"\"\n",
        "\n",
        "if os.path.isfile(interview_answers_path):\n",
        "  df_interview_answers = pd.read_excel(interview_answers_path, index_col=0)\n",
        "\n",
        "print(f\"Start Processing: \", datetime.now())\n",
        "print(\"Progress: \", end=\"\")\n",
        "for i, r in df_interview_answers.iterrows():\n",
        "  if i%10 == 0:\n",
        "      print(\".\", end=\"\")\n",
        "\n",
        "  response = str(r.Response).strip().lower()\n",
        "\n",
        "  if (len(response)<1 or response==\"nan\"):\n",
        "    (answer, duration, prompt) = skills_interview_llm(r)\n",
        "\n",
        "    df_interview_answers.loc[df_interview_answers.index == i, [response_col]] = answer\n",
        "    df_interview_answers.loc[df_interview_answers.index == i, [duration_col]] = duration\n",
        "    df_interview_answers.loc[df_interview_answers.index == i, [prompt_col]] = prompt\n",
        "\n",
        "    if i>0 and i%50==0:\n",
        "        print(\"\\nSaving Progress: \", i, datetime.now())\n",
        "        df_interview_answers.to_excel(interview_answers_path)\n",
        "\n",
        "print(f\"\\nEnd Processing: \", datetime.now())\n",
        "df_interview_answers.to_excel(interview_answers_path)\n",
        "\n",
        "print(\"Completed.\")"
      ],
      "metadata": {
        "id": "fXVwKNXY-R4v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deeaa037-cb45-4cdd-befb-153d2be300f8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process interview questions...\n",
            "Start Processing:  2025-04-10 22:23:58.254961\n",
            "Progress: .\n",
            "End Processing:  2025-04-10 22:24:50.006122\n",
            "Completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing: Personality Likert"
      ],
      "metadata": {
        "id": "bhRkdlENmFsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Process personality likert questions...\")\n",
        "\n",
        "# Extract Personality Likert Questions\n",
        "df_personality_likert = df_combined[(df_combined[item_col].str.startswith(personality_likert_item_prefix))].copy()\n",
        "\n",
        "# Keep only unique cases\n",
        "df_personality_likert = df_personality_likert[[question_col]].copy()\n",
        "df_personality_likert.drop_duplicates(inplace=True)\n",
        "df_personality_likert.reset_index(drop=True, inplace=True)\n",
        "df_personality_likert.index = df_personality_likert.index + 1\n",
        "df_personality_likert.rename_axis(id_col, inplace=True)\n",
        "\n",
        "df_personality_likert.to_excel(personality_likert_path)\n",
        "\n",
        "df_personality_likert_answers = df_personality_likert.copy()\n",
        "df_personality_likert_answers[response_col] = \"\"\n",
        "df_personality_likert_answers[duration_col] = \"\"\n",
        "df_personality_likert_answers[prompt_col] = \"\"\n",
        "\n",
        "if os.path.isfile(personality_likert_answers_path):\n",
        "  df_personality_likert_answers = pd.read_excel(personality_likert_answers_path, index_col=0)\n",
        "\n",
        "print(f\"Start Processing: \", datetime.now())\n",
        "print(\"Progress: \", end=\"\")\n",
        "for i, r in df_personality_likert_answers.iterrows():\n",
        "  if i%10 == 0:\n",
        "      print(\".\", end=\"\")\n",
        "\n",
        "  response = str(r.Response).strip().lower()\n",
        "\n",
        "  if (len(response)<1 or response==\"nan\"):\n",
        "    (answer, duration, prompt) = personality_likert_llm(r)\n",
        "\n",
        "    df_personality_likert_answers.loc[df_personality_likert_answers.index == i, [response_col]] = answer\n",
        "    df_personality_likert_answers.loc[df_personality_likert_answers.index == i, [duration_col]] = duration\n",
        "    df_personality_likert_answers.loc[df_personality_likert_answers.index == i, [prompt_col]] = prompt\n",
        "\n",
        "    if i>0 and i%50==0:\n",
        "        print(\"\\nSaving Progress: \", i, datetime.now())\n",
        "        df_personality_likert_answers.to_excel(personality_likert_answers_path)\n",
        "\n",
        "print(f\"\\nEnd Processing: \", datetime.now())\n",
        "df_personality_likert_answers.to_excel(personality_likert_answers_path)\n",
        "\n",
        "print(\"Completed.\")"
      ],
      "metadata": {
        "id": "OFi01XTSmK1M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "492f45e3-d6b5-44d8-ce59-bc6ef347eba6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process personality likert questions...\n",
            "Start Processing:  2025-04-10 22:24:50.046143\n",
            "Progress: .....\n",
            "Saving Progress:  50 2025-04-10 22:25:16.979845\n",
            ".....\n",
            "Saving Progress:  100 2025-04-10 22:25:42.741419\n",
            "..\n",
            "End Processing:  2025-04-10 22:25:54.684609\n",
            "Completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing: Personality Choice"
      ],
      "metadata": {
        "id": "ZmX_ht0mFPFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Process personality choice questions...\")\n",
        "\n",
        "# Extract Personality Choice Questions\n",
        "df_personality_choice = df_combined[(df_combined[item_col].str.startswith(personality_choice_item_prefix))].copy()\n",
        "\n",
        "# Keep only unique cases\n",
        "df_personality_choice = df_personality_choice[[question_col]].copy()\n",
        "df_personality_choice.drop_duplicates(inplace=True)\n",
        "df_personality_choice.reset_index(drop=True, inplace=True)\n",
        "df_personality_choice.index = df_personality_choice.index + 1\n",
        "df_personality_choice.rename_axis(id_col, inplace=True)\n",
        "\n",
        "df_personality_choice.to_excel(personality_choice_path)\n",
        "\n",
        "df_personality_choice_answers = df_personality_choice.copy()\n",
        "df_personality_choice_answers[response_col] = \"\"\n",
        "df_personality_choice_answers[duration_col] = \"\"\n",
        "df_personality_choice_answers[prompt_col] = \"\"\n",
        "\n",
        "if os.path.isfile(personality_choice_answers_path):\n",
        "  df_personality_choice_answers = pd.read_excel(personality_choice_answers_path, index_col=0)\n",
        "\n",
        "print(f\"Start Processing: \", datetime.now())\n",
        "print(\"Progress: \", end=\"\")\n",
        "\n",
        "messages = []\n",
        "\n",
        "formatted_system_prompt = personality_choice_system_prompt + \"\\n\\n\" + personality_choice_question_prefix\n",
        "\n",
        "messages.append({\n",
        "    \"role\": \"system\",\n",
        "    \"content\": f\"{formatted_system_prompt}\"\n",
        "})\n",
        "\n",
        "for i, r in df_personality_choice_answers.iterrows():\n",
        "  if i%10 == 0:\n",
        "      print(\".\", end=\"\")\n",
        "\n",
        "  user_prompt = r.Question.replace(personality_choice_question_prefix, \"\").strip()\n",
        "\n",
        "  messages.append({\n",
        "      \"role\": \"user\",\n",
        "      \"content\": f\"{user_prompt}\"\n",
        "  })\n",
        "\n",
        "  response = str(r.Response).strip().lower()\n",
        "\n",
        "  if (len(response)<1 or response==\"nan\"):\n",
        "    (answer, duration, prompt) = personality_choice_llm(r, messages)\n",
        "\n",
        "    df_personality_choice_answers.loc[df_personality_choice_answers.index == i, [response_col]] = answer\n",
        "    df_personality_choice_answers.loc[df_personality_choice_answers.index == i, [duration_col]] = duration\n",
        "    df_personality_choice_answers.loc[df_personality_choice_answers.index == i, [prompt_col]] = prompt\n",
        "\n",
        "    if i>0 and i%50==0:\n",
        "        print(\"\\nSaving Progress: \", i, datetime.now())\n",
        "        df_personality_choice_answers.to_excel(personality_choice_answers_path)\n",
        "  else:\n",
        "    answer = r.Response\n",
        "\n",
        "  messages.append({\n",
        "      \"role\": \"assistant\",\n",
        "      \"content\": f\"{answer}\"\n",
        "  })\n",
        "\n",
        "print(f\"\\nEnd Processing: \", datetime.now())\n",
        "df_personality_choice_answers.to_excel(personality_choice_answers_path)\n",
        "\n",
        "print(\"Completed.\")"
      ],
      "metadata": {
        "id": "Nd3FWJK4FQT8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cd71793-31c2-438a-c17b-ba26e9af2f9e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process personality choice questions...\n",
            "Start Processing:  2025-04-10 22:25:54.732247\n",
            "Progress: .....\n",
            "Saving Progress:  50 2025-04-10 22:29:30.525290\n",
            "\n",
            "End Processing:  2025-04-10 22:29:34.567570\n",
            "Completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Answers: All"
      ],
      "metadata": {
        "id": "x6ayyYVRwcHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Consolidate all answers...\")\n",
        "\n",
        "df_answers = df_combined.copy()\n",
        "\n",
        "stop_at_index = None\n",
        "\n",
        "print(f\"Start Processing: \", datetime.now())\n",
        "try:\n",
        "  for i, r in df_answers.iterrows():\n",
        "      if i%1000 == 0:\n",
        "          print(\".\", end=\"\")\n",
        "\n",
        "      (answer, duration, prompt) = answer_job_application(r)\n",
        "\n",
        "      df_answers.loc[df_answers.index == i, [response_col]] = answer\n",
        "      df_answers.loc[df_answers.index == i, [duration_col]] = duration\n",
        "      df_answers.loc[df_answers.index == i, [prompt_col]] = prompt\n",
        "\n",
        "      if i>0 and i%5000==0:\n",
        "          print(\"\\nSaving Progress: \", i, datetime.now())\n",
        "          df_answers.to_excel(answers_path)\n",
        "\n",
        "      if stop_at_index and i>=stop_at_index:\n",
        "          print(\"\\nStop: \", i, datetime.now())\n",
        "          break\n",
        "except Exception as e:\n",
        "  print(f\"Id {i}: {e}\")\n",
        "  raise Exception(e)\n",
        "\n",
        "print(f\"\\nEnd Processing: \", datetime.now())\n",
        "\n",
        "df_answers.to_excel(answers_path)\n",
        "\n",
        "print(\"Completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWqpoMtwwe-1",
        "outputId": "7c524f0c-5027-4125-f60e-b40afbb0fee7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Consolidate all answers...\n",
            "Start Processing:  2025-04-10 22:29:34.604165\n",
            "\n",
            "End Processing:  2025-04-10 22:29:36.372167\n",
            "Completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission Prep"
      ],
      "metadata": {
        "id": "TIPMMoaD_l4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Prepare submission file...\")\n",
        "\n",
        "# Save Updates to Unscramble Dictionary\n",
        "df_unscramble = pd.DataFrame.from_dict(unscramble_dict)\n",
        "df_unscramble.rename_axis(id_col, inplace=True)\n",
        "df_unscramble.to_excel(unscramble_lookup_path)\n",
        "\n",
        "# Create Submission File\n",
        "df_answers.sort_values(id_col, inplace=True)\n",
        "\n",
        "df_submit = df_answers[submit_keep_cols].copy()\n",
        "df_submit.to_excel(submit_path, index=False)\n",
        "\n",
        "# Check Submission File for Missing Responses\n",
        "validate_submission(df_submit)\n",
        "\n",
        "print(\"Completed.\")"
      ],
      "metadata": {
        "id": "K5DTNV9C_meO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bd98532-f8cb-4b25-f2e1-992b018ad8d7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prepare submission file...\n",
            "Completed.\n"
          ]
        }
      ]
    }
  ]
}